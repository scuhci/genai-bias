# Generative AI Bias: Analysing Gender & Racial Bias in Generative AI User Personas

The Generative AI Bias (GenAI Bias) project provides an in-depth analysis of how gender and racial bias is demonstrated in generative AI text. In particular, we focus on the gender and racial bias present during the task of generating large batches of â€œuser personaâ€ data. We examine four state of the art chatbots - ChatGPT, Gemini, Mistral, and DeepSeek - and 40 careers, then conduct thorough data analysis to determine underlying patterns indicative of stereotype or bias.

**This project is stil a work in progress.**

## Team

This project was made with love at the [Santa Clara University HCI Lab](https://scuhci.com/) by a student-led team of researchers. 

**Faculty Advisor** :bulb:
- Professor Kai Lukoff | [Website](https://kailukoff.com/)

**Project Lead** âœï¸
- Ilona van der Linden | [LinkedIn](https://www.linkedin.com/in/lonavdlin/) | [Email](mailto:lonavdlin@gmail.com)

**Research Team** ğŸ“–
- Arnav Dixit | [LinkedIn](https://www.linkedin.com/in/arnav-dixit/) | [Email](mailto:dixitarnav2@gmail.com)
- Smruthi Danda | [LinkedIn](https://www.linkedin.com/in/smruthi-danda/) 
- Aadi Sudan | [LinkedIn](https://www.linkedin.com/in/aadi-sudan-66b183204/) | [Email](mailto:aadisudan123@gmail.com)
- Sahana Kumar | [LinkedIn](https://www.linkedin.com/in/sahana-kumar-7501401b0/) | [Email](mailto:sahana@anands.net)
