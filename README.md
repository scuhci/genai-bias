# Generative AI Bias: Analysing Gender & Racial Bias in Generative AI User Personas

The Generative AI Bias (GenAI Bias) project provides an in-depth analysis of how gender and racial bias is demonstrated in generative AI text. In particular, we focus on the gender and racial bias present during the task of generating large batches of “user persona” data. We examine three state of the art chatbots - ChatGPT, Gemini, and Claude - and 40 careers, then conduct thorough data analysis to determine underlying patterns indicative of stereotype or bias in each chatbot.

**This project is stil a work in progress.**

## Team

This project was made with love at the [Santa Clara University HCI Lab](https://scuhci.com/) by a student-led team of researchers. It is also the ongoing thesis work of Ilona van der Linden for the Santa Clara University Depeartment of Computer Science & Engineering.

**Faculty Advisor** :bulb:
- Professor Kai Lukoff | [Website](https://kailukoff.com/)

**Project Lead** ✏️
- Ilona van der Linden | [LinkedIn](https://www.linkedin.com/in/lonavdlin/) | [Email](mailto:lonavdlin@gmail.com)

**Research Team** 📖
- Arnav Dixit | [LinkedIn](https://www.linkedin.com/in/arnav-dixit/) | [Email](mailto:dixitarnav2@gmail.com)
- Smruthi Danda | [LinkedIn](https://www.linkedin.com/in/smruthi-danda/) 
- Aadi Sudan | [LinkedIn](https://www.linkedin.com/in/aadi-sudan-66b183204/) | [Email](mailto:aadisudan123@gmail.com)
- Sahana Kumar | [LinkedIn](https://www.linkedin.com/in/sahana-kumar-7501401b0/) | [Email](mailto:sahana@anands.net)
